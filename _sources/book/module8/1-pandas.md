# การจัดการข้อมูลด้วย pandas

ข้อมูลแบบตาราง (tabular data) เป็นรูปแบบข้อมูลที่ได้รับความนิยมอย่างมากในงานประมวลผลและวิเคราะห์ข้อมูล เนื่องจากมีโครงสร้างที่เป็นระเบียบและการจัดเก็บข้อมูลที่สามารถเข้าถึงได้ง่าย แต่ละแถวแทนหนึ่งรายการหรือตัวอย่าง และแต่ละคอลัมน์มีค่าของตัวแปรหนึ่งตัว ซึ่งช่วยให้สามารถจัดการและวิเคราะห์ข้อมูลได้อย่างมีประสิทธิภาพ เราจึงจัดว่าข้อมูลแบบตารางเป็นข้อมูลที่มีโครงสร้าง (structured data) และเป็นรูปแบบการจัดเก็บข้อมูลในอุดมคติ พร้อมสำหรับการวิเคราะห์

```{margin} คำศัพท์
ข้อมูลแบบตาราง (tabular data)
```

ในการจัดการกับข้อมูลชนิดนี้ เรามักใช้ pandas ซึ่งเป็นไลบรารีของภาษาไพธอน ที่ประกอบไปด้วยเครื่องมือระดับสูงสำหรับการจัดการข้อมูลแบบตาราง ไลบรารี pandas ทำงานร่วมกับข้อมูลขนาดใหญ่ได้ดี รวมถึงมีฟังก์ชันต่างๆ สำหรับการเลือก กรอง และปรับแต่งข้อมูลได้อย่างง่ายดาย นอกจากนี้ยังสามารถรวมข้อมูลจากแหล่งข้อมูลหลายแห่งและรองรับการอ่านและเขียนไฟล์ข้อมูลในรูปแบบต่างๆ ได้อย่างหลากหลาย ทำให้เป็นเครื่องมือที่ทรงพลังและได้รับความนิยมสูงในการวิเคราะห์ข้อมูลแบบตาราง การใช้ pandas นับเป็นทักษะที่สำคัญที่สุดอย่างหนึ่งของนักวิเคราะห์ข้อมูล โดยเฉพาะอย่างยิ่งข้อมูลที่เป็นข้อความ และข้อมูลที่มีขนาดใหญ่เกินกว่าที่จะเปิดด้วยโปรแกรมวิเคราะห์ข้อมูลทั่วไป เช่น SPSS Microsoft Excel หรือ Google Spreadsheet

หากเราติดตั้งไพธอนผ่าน Anaconda เราจะได้ไลบรารี pandas มาพร้อมกับการติดตั้ง แต่หากเราใช้งานไพธอนผ่านการติดตั้งแบบอื่น เราสามารถติดตั้งไลบรารี pandas ได้โดยการใช้คำสั่ง `pip install pandas` หรือ `conda install pandas` (หากติดตั้ง miniconda) เมื่อติดตั้งเสร็จเรียบร้อยแล้ว เราสามารถนำเข้าไลบรารี pandas ได้โดยการใช้คำสั่ง `import pandas as pd` ซึ่งจะทำให้เราสามารถใช้ฟังก์ชันและเมธอดที่อยู่ในไลบรารี pandas ได้ 

เราอาจจะสงสัยว่าเพราะเหตุใดเราต้องเปลี่ยนชื่อไลบรารีเป็น `pd` โดยการรัน `import pandas as pd` ซึ่งเราไม่จำเป็นต้องเปลี่ยนชื่อก็สามารถใช้ได้เหมือนกัน แต่เราเลือกเปลี่ยนชื่อเป็น `pd` เพื่อให้เราสามารถเขียนโค้ดได้สั้นลง  นอกจากนั้นเราไม่ใช้ชื่ออื่นเช่น `p` หรือ `pan` หรือชื่ออื่นๆ ที่เราเลือกเอง เหตุก็เพราะว่า `pd` จะเป็นชื่อที่คนในวงการวิทยาการข้อมูลใช้กันมากที่สุด อย่างที่เราเห็นได้ว่าหากเราไปค้นหาวิธีการใช้งานของ pandas ในเว็บไซต์ที่รวมชุมชนนักวิเคราะห์ข้อมูล เช่น stackoverflow.com หรือ medium.com จะพบว่าคำตอบจะใช้ `pd` ในการอ้างถึงไลบรารี pandas ทั้งสิ้นด้วย ดังนั้นการใช้ชื่อ `pd` เป็นการตั้งชื่อตามสมัยนิยม และเป็นการให้ความสะดวกในการเรียนรู้จากแหล่งข้อมูลอื่นๆ ที่มีอยู่ในอินเทอร์เน็ต

## การเตรียมและวิเคราะห์ข้อมูลด้วย Jupyter notebook 

Jupyter notebook เป็น IDE ที่ถูกออกแบบมาเพื่อการวิเคราะห์ข้อมูลโดยเฉพาะ เพราะว่าการวิเคราะห์ข้อมูลจำเป็นต้องมีการบันทึกว่าเราได้แก้ไขชุดข้อมูลอย่างไรบ้าง รันโค้ดอะไรบ้างที่นำไปสู่ผลการวิเคราะห์ เราจึงเรียกว่า notebook เพราะเปรียบเสมือนการจดบันทึกการวิเคราะห์ข้อมูล เพื่อให้ฟังดูคล้ายคลึงนักวิทยาศาสตร์จดบันทึกผลการทดลอง ด้วยเหตุนี้เอง Jupyter notebook จึงมีการออกลูกเล่น ฟีเจอร์ใหม่อย่างต่อเนื่อง เพื่ออำนวยความสะดวกในการวิเคราะห์ข้อมูล เช่น

- แสดงผลข้อมูลตารางออกมาในรูปแบบที่อ่านได้ง่าย ไม่ล้นออกมาทั้งแนวตั้งและแนวนอน ทำให้ตรวจสอบข้อมูลได้ง่าย ข้อผิดพลาดน้อยลง

- แสดงแผนภูมิออกมาตามคำสั่งของไลบรารี โดยไม่ต้องเก็บภาพใส่ไฟล์แยกต่างหาก  ทำให้สามารถแก้ไขและปรับแต่งแผนภูมิได้ง่าย ทั้งแผนภูมิ และโค้ดที่ใช้สร้างแผนภูมิอยู่ข้างกัน 

- สามารถใช้ extension บน Visual Studio Code หรือ Google Colab ที่ทำให้วิเคราะห์ข้อมูลเชิงโต้ตอบ (interactive) ได้คล้ายคลึงกับการใช้โปรแกรมวิเคราะห์ข้อมูลอื่น ๆ ที่มี user interface สวยงามและสะดวกในการใช้งาน 

ด้วยข้อดีดังกล่าวข้างต้นวงการวิทยาการข้อมูลจึงนิยมใช้ pandas บน Jupyter notebook ในการเตรียมข้อมูลและวิเคราะห์ข้อมูล  ซึ่งจัดเป็นแนวปฏิบัติที่ดีที่สุดในขณะนี้

## ข้อมูลแบบตาราง
ข้อมูลแบบตารางมีส่วนประกอบหลักที่สำคัญอยู่หลายส่วน ซึ่งแต่ละส่วนมีบทบาทสำคัญในการเก็บรักษาและการจัดการข้อมูล

1. แถว (row) แสดงถึงรายการหรือตัวอย่างแต่ละชิ้น ที่ซึ่งข้อมูลสามารถอธิบายลักษณะหรือสถานะของเหตุการณ์ วัตถุ หรือบุคคลที่กำลังศึกษาอยู่ ตัวอย่างเช่น ในตารางข้อมูลของผู้ป่วย แต่ละแถวอาจแทนผู้ป่วยหนึ่งคนพร้อมกับรายละเอียดต่างๆ เช่น อายุ เพศ และประวัติการรักษา
2. คอลัมน์ (column) แสดงถึงตัวแปรหรือคุณลักษณะที่ระบุค่าข้อมูลต่างๆ ที่จำเป็นต่อการศึกษาหรือวิเคราะห์ ตัวอย่างเช่น ในตารางข้อมูลการขาย คอลัมน์อาจประกอบด้วย วันที่ จำนวนเงิน และสินค้าที่ขาย
3. หัวตาราง (header) เป็นบรรทัดแรกของตารางที่ระบุชื่อของแต่ละคอลัมน์ เป็นส่วนที่สำคัญเพราะช่วยให้ผู้ใช้สามารถเข้าใจข้อมูลในแต่ละคอลัมน์ได้ง่ายและชัดเจน
4. ตัวข้อมูล (data) เป็นสาระสำคัญที่แสดงถึงค่าเฉพาะของแต่ละรายการตามที่ถูกกำหนดไว้ในคอลัมน์ ข้อมูลนี้สามารถเป็นตัวเลข ข้อความ วันที่ หรือแบบชนิดข้อมูล (data type) อื่นๆ ที่เหมาะสมกับลักษณะของการศึกษา เพราะฉะนั้นข้อมูลที่อยู่ในคอลัมน์เดียวกันจะต้องเป็นแบบชนิดข้อมูลเดียวกัน เนื่องจากเป็นตัวแปรชนิดเดียวกัน 

```{figure} img/row-column2.png
ส่วนประกอบที่สำคัญของข้อมูลแบบตาราง (ข้อมูลดัดแปลงจาก Airline Reviews Dataset จาก airlinequality.com)
```

ส่วนประกอบอีกอย่างหนึ่งที่สำคัญของข้อมูลแบบตารางคือ พจนานุกรมข้อมูล (data dictionary) ซึ่งเป็นเอกสารที่ระบุความหมายของแต่ละคอลัมน์ และค่าข้อมูลที่เป็นไปได้ของแต่ละคอลัมน์ ซึ่งช่วยให้ผู้ใช้เข้าใจข้อมูลได้ง่ายขึ้น และช่วยให้ผู้ใช้สามารถใช้ข้อมูลได้อย่างถูกต้องและเหมาะสม พจนานุกรมข้อมูลนี้มักจะถูกเก็บแยกออกมาอีกไฟล์หนึ่ง หรือเป็นส่วนหนึ่งของเอกสารคู่มือการใช้งานข้อมูล แต่ในหลาย ๆ กรณีผู้ดูแลรักษาข้อมูลอาจจะไม่ได้เตรียมพจนานุกรมข้อมูลเอาไว้ให้พร้อมใช้ ผู้ใช้ข้อมูลจะต้องไปสอบถามผู้ดูแลรักษาข้อมูลหรือค้นหาข้อมูลเพิ่มเติมเองโดยตรง ตัวอย่างของพจนานุกรมข้อมูลของข้อมูลการรีวิวสายการบิน อาจมีดังนี้

| ชื่อคอลัมน์ | คำอธิบาย | ค่าที่เป็นไปได้ |
|--------------|-----------|------------------|
| Airline Name | ชื่อสายการบิน | ชื่อสายการบิน |
| Rating | คะแนนการรีวิว | 1-10 |
| Seat Type | ประเภทที่นั่ง | Economy, Premium Economy, Business, First |
| Verified | การยืนยันตัวตน | TRUE, FALSE |
| Date Flown | วันที่เดินทาง | วันที่เดินทางเป็นเดือนและปี |


## กระบวนการเตรียมข้อมูลสำหรับการวิเคราะห์ 

ไลบรารี pandas มีฟังก์ชันต่าง ๆ ที่ช่วยในการจัดการข้อมูลแบบตาราง ซึ่งเป็นกระบวนการที่สำคัญในการวิเคราะห์ข้อมูล โดยปกติแล้วกระบวนการเตรียมข้อมูลสำหรับการวิเคราะห์จะประกอบด้วยขั้นตอนดังนี้

1. การทำความสะอาดข้อมูล (data cleaning) คือ การคัดแยกข้อมูลที่สกปรกออกไป เช่น ข้อมูลที่สมบูรณ์ สั้นเกินไป ยาวเกินไป ผิดเพี้ยน หรือข้อความมีข้อมูลเราไม่ต้องการเช่น url หรือเครื่องหมายวรรคตอน หรือ สิ่งอื่น ๆ ที่อาจจะทำให้การวิเคราะห์ข้อมูลคลาดเคลื่อนไปได้

2. การวิเคราะห์ข้อมูลเชิงสำรวจ (exploratory data analysis: EDA) คือ การวิเคราะห์เพื่อให้เราเข้าใจข้อมูลคร่าว ๆ เนื่องจากข้อมูลมักจะมีขนาดใหญ่มาก เราไม่สามารถนำข้อมูลออกมาดูได้ทั้งหมด เรามักจะทำ EDA โดยดูว่าข้อมูลมีทั้งหมดที่แถว แต่ละคอลัมน์เก็บข้อมูลอะไรอยู่บ้าง แต่ละคอลัมน์มีค่าสูงสุด ต่ำสุดเท่าไร ถ้าเป็นข้อความ ข้อความที่ยาวสุดยาวกี่ตัวอักษร สั้นสุดกี่ตัวอักษร เป็นต้น 

3. การขยำข้อมูล (data munging ซึ่งเป็นศัพท์แสลงที่ใช้ในวงการวิทยาการข้อมูล) หรือ การทะเลาะกับข้อมูล (data wrangling ซึ่งเป็นศัพท์ที่ทางการขึ้น) คือ การแปลงข้อมูลจากรูปเดิม นำมาทำความสะอาด และคัดให้เหลืออยู่เฉพาะส่วนที่สำคัญเพื่อนำไปวิเคราะห์ต่อ อาทิ ลบคอลัมน์ที่ไม่เกี่ยวข้องกับการวิเคราะห์  เปลี่ยนชื่อคอลัมน์ให้สื่อความหมาย ลบคอลัมน์ที่ซ้ำซ้อนกันออกไป ลบแถวที่มีข้อมูลที่สกปรก คลาดเคลื่อนมากจนใช้การไม่ได้ ลบแถวที่ซ้ำซ้อนกันออกไป แปลงหน่วยวัด แปลงแบบชนิดข้อมูลในแต่ละคอลัมน์ หรือควบรวมเอาข้อมูลจากหลายแหล่งมารวมกัน
```{margin} คำศัพท์
การวิเคราะห์ข้อมูลเชิงสำรวจ (exploratory data analysis)
```

## รูปแบบการจัดเก็บข้อมูลแบบตาราง

ข้อมูลแบบตารางสามารถเก็บได้ในหลายรูปแบบไฟล์ (file format) ที่มีลักษณะและคุณสมบัติที่ต่างกัน ทำให้เหมาะสมกับการใช้งานในสถานการณ์ที่ต่างกันด้วย รูปแบบไฟล์ที่พบบ่อยมีดังนี้

### ไฟล์ CSV (comma-separated value) และ TSV (tab-separated value)
```{margin} คำศัพท์
อักขระคั่น (delimiter)
```
ไฟล์ CSV (comma-separated value) สกุลของไฟล์คือ .csv ถูกจัดเก็บในลักษณะที่ง่ายและเป็นระเบียบเพื่อให้ง่ายต่อการเข้าใจและใช้งานได้กับโปรแกรมหลากหลายชนิด หลักการหลักของการเก็บข้อมูลแบบ CSV ได้แก่ 

1. ใช้เครื่องหมายจุลภาค (comma) เป็นอักขระคั่น (delimiter) ซึ่งเป็นอักขระที่ทำหน้าที่ตัวแบ่งระหว่างข้อมูลในแต่ละคอลัมน์2. ใช้สัญลักษณ์พิเศษ `\n` ในการบ่งบอกว่าข้อมูลในแถวนั้นจบลงแล้ว และข้อมูลในแถวถัดไปจะเริ่มต้นขึ้นใหม่ถ้าหากยังมีข้อมูลเพิ่มเติมอีก
3. ข้อมูลที่เป็นข้อความจะถูกครอบด้วยเครื่องหมายคำพูด เพื่อป้องกันการสับสนกับอักขระคั่น หรืออักขระที่ใช้ในการขึ้นบรรทัดใหม่

โดยปกติไฟล์ CSV จะเริ่มต้นด้วยบรรทัดหัวตารางที่บอกชื่อคอลัมน์ ชื่อคอลัมน์แต่ละชื่อถูกแบ่งด้วยจุลภาค ตามด้วยข้อมูลในแต่ละแถว โดยข้อมูลแต่ละชิ้นในแถวเดียวกันจะถูกแบ่งออกจากกันด้วยจุลภาค
แต่ละแถวของข้อมูลจะถูกแยกออกจากกันด้วยการขึ้นบรรทัดใหม่ หากตัวข้อมูลเองมีเครื่องหมายจุลภาคหรือการขึ้นบรรทัดใหม่ ข้อมูลนี้ต้องถูกครอบด้วยเครื่องหมายคำพูดเพื่อไม่ให้เกิดความสับสนในโครงสร้างของไฟล์ ตัวอย่างเช่น 
```
Airline Name,Rating,Seat Type,Verified,Date Flown
Bangkok Airways,6,Economy,TRUE,March 2019
Bangkok Airways,9,Economy,TRUE,June 2019
Bangkok Airways,1,Economy,FALSE,November 2021
Bangkok Airways,9,Economy,FALSE,April 2020
Garuda Indonesia,1,Economy,TRUE,July 2023
Garuda Indonesia,9,Business,TRUE,January 2020
Garuda Indonesia,9,Business,TRUE,February 2020
Philippine Airlines,8,Economy,TRUE,April 2023
Philippine Airlines,7,Premium Economy,FALSE,January 2023
Philippine Airlines,1,Economy,TRUE,July 2023
```
ชุดข้อมูลในไฟล์ CSV ข้างต้นประกอบไปด้วยคอลัมน์ 5 คอลัมน์ ชื่อว่า 
- Airline Name
- Rating
- Seat Type
- Verified
- Date Flown

ซึ่งถูกเก็บอยู่ในหัวตารางในบรรทัดแรก และประกอบไปด้วยแถว 10
 แถวซึ่งเก็บข้อมูลของการรีวิวให้คะแนนจากผู้โดยสารของสายการบินต่างๆ แต่ละคน แต่ละเที่ยวบิน

รูปแบบไฟล์ CSV คือมีโครงสร้างที่ง่าย ยืดหยุ่น และสามารถใช้กับโปรแกรมได้หลากหลายตัว จึงเป็นที่นิยมมาก ตัวอย่างเช่น เราสามารถใช้ visual studio code เปิดไฟล์ csv เพื่อตรวจสอบข้อมูลเบื้องต้นได้ เพราะเป็นรูปแบบไฟล์ที่มนุษย์อ่านได้ (human-readable format) และเป็นจะเป็นรูปแบบไฟล์ที่เราจะใช้เป็นตัวอย่างในบทนี้ อย่างไรก็ตามหากตัวข้อมูลเองมีการขึ้นบรรทัดใหม่ เช่น เรียงความ บทความ หรือทวีต จะทำให้ไฟล์ซับซ้อนขึ้นมาก เพราะว่าต้องมีการแบ่งแยกว่าการขึ้นบรรทัดใหม่แสดงถึง แถวใหม่ หรือเป็นการขึ้นบรรทัดใหม่ในสตริงที่เก็บอยู่ในตัวข้อมูลเอง ทำให้ไฟล์ csv ที่เรานับว่าเป็นไฟลที่มนุษย์อ่านได้กลายเป็นไฟล์ที่อ่านได้ยาก หากเราใช้ไลบรารี pandas หรือโปรแกรม Excel ในการจัดการข้อมูล CSV ตัวไลบรารีเองมักจะแก้ไขปัญหาเหล่านี้ให้

นอกจากนั้นยังมีไฟล์ตระกูล .tsv ซึ่งย่อมาจาก tab-separated value ไฟล์ TSV ที่จริงแล้วมีรูปแบบการเก็บข้อมูลใกล้เคียงกันกับไฟล์ CSV เพียงแค่เปลี่ยนตัวแบ่งระหว่างข้อมูลในแต่ละคอลัมน์เป็นแท็บ (`\t`) แทนที่จุลภาค ข้อดีของการใช้แท็บแทนจุลภาคคือ แท็บแสดงผลออกมาเป็นการเว้นระยะทำให้เห็นความแบ่งแยกระหว่างคอลัมน์ที่ชัดเจนและเป็นระเบียบ ได้ดีกว่าเมื่อเปิดด้วยโปรแกรมแก้ไขข้อความธรรมดา ทำให้เหมาะสำหรับการตรวจสอบข้อมูลด้วยตาเปล่าหรือการปรับแต่งข้อมูลเบื้องต้น ตัวอย่างเช่น 
```
Airline Name	Rating	Seat Type	Verified	Date Flown
Bangkok Airways	6	Economy	TRUE	March 2019
Bangkok Airways	9	Economy	TRUE	June 2019
Bangkok Airways	1	Economy	FALSE	November 2021
Bangkok Airways	9	Economy	FALSE	April 2020
Garuda Indonesia	1	Economy	TRUE	July 2023
Garuda Indonesia	9	Business	TRUE	January 2020
Garuda Indonesia	9	Business	TRUE	February 2020
Philippine Airlines	8	Economy	TRUE	April 2023
Philippine Airlines	7	Premium Economy	FALSE	January 2023
Philippine Airlines	1	Economy	TRUE	July 2023
```
จากตัวอย่างข้างต้นจะเห็นว่าข้อมูลในแต่ละคอลัมน์ซึ่งถูกแบ่งด้วยแท็บ ซึ่งถูกแสดงผลออกมาเป็นเหมือนการเคาะเว้นระยะทำให้เห็นความแบ่งแยกระหว่างคอลัมน์ที่ชัดเจนและเป็นระเบียบขึ้น แต่ว่าแต่ละคอลัมน์อาจจะไม่แสดงผลตรงกันหมดทุกบรรทัด ขึ้นอยู่กับความสั้นยาวของตัวข้อมูลในแต่ละคอลัมน์เอง 

ทั้งไฟล์ CSV และ TSV ต่างเป็นไฟล์ที่ได้รับความนิยมในวงการวิทยาการข้อมูล เนื่องจากมีโครงสร้างที่ง่าย มนุษย์สามารถอ่านได้ และสามารถใช้กับโปรแกรมหลายตัวได้ ทำให้เหมาะสำหรับการใช้งานในสถานการณ์ที่ต่างกัน รวมถึงรองรับการบันทึกชุดข้อมูลขนาดใหญ่อีกด้วย 

### ไฟล์ Excel 

ไฟล์ Excel เป็นรูปแบบไฟล์ที่ใช้กับโปรแกรม Microsoft Excel ซึ่งเป็นส่วนหนึ่งของชุดโปรแกรม Microsoft Office โดยไฟล์ Excel มักมีนามสกุลไฟล์เป็น .xls หรือ .xlsx สำหรับ Microsoft Office เวอร์ชันใหม่กว่า ซึ่งใช้รูปแบบการเก็บข้อมูลที่ซับซ้อนและสามารถรองรับคุณสมบัติต่างๆ ได้หลากหลายมากกว่า CSV ได้แก่

1. *เวิร์กชีต (worksheet)* ข้อมูลใน Excel จะถูกจัดเก็บในเวิร์กชีตซึ่งแต่ละเวิร์กชีตสามารถมีข้อมูลแบบตารางได้ โดยผู้ใช้สามารถมีหลายเวิร์กชีตภายในไฟล์เดียว
2. *เซลล์ (cell)* ข้อมูลในเวิร์กชีตจะถูกจัดเก็บในเซลล์ โดยแต่ละเซลล์สามารถรองรับข้อมูลได้ทั้งข้อความ, ตัวเลข, สูตรการคำนวณ, หรือแม้กระทั่งกราฟิก
3. *สูตร* Excel รองรับสูตรการคำนวณที่ช่วยให้สามารถประมวลผลข้อมูลจากเซลล์ต่างๆ และอัปเดตผลลัพธ์อัตโนมัติเมื่อข้อมูลเปลี่ยนแปลง
4. *การจัดรูปแบบ* สามารถกำหนดรูปแบบให้กับข้อมูลได้อย่างละเอียด เช่น สี, ขนาด, และประเภทของตัวอักษร, การจัดตำแหน่ง, การใส่กรอบเซลล์, และอื่นๆ

การจัดการและวิเคราะห์ข้อมูลด้วยโปรแกรม Microsoft Excel และไฟล์ตระกูล .xlsx เป็นที่นิยมเป็นอย่างมาก เนื่องจากมีฟีเจอร์หลากหลาย รองรับงานคำนวณตั้งแต่ขั้นเบื้องต้นจนไปถึงขั้นสูง ใช้งานค่อนข้างสะดวกสบายมีการแสดงผลที่สวยงาม สามารถจัดรูปแบบให้เกิดความโดดเด่น และความชัดเจนในการวิเคราะห์ข้อมูลได้ ทักษะการใช้โปรแกรมประเภทนี้เป็นทักษะจำเป็นอย่างยิ่งสำหรับนักวิเคราะห์ข้อมูล และนักวิทยาการข้อมูลทุกคน แต่ว่าข้อจำกัดที่สำคัญที่สุดของการใช้ Excel คือการรับมือกับข้อมูลขนาดใหญ่ที่มีจำนวนคอลัมน์มากจนไม่สามารถแสดงผลออกมาบนหน้าจอได้หมด หรือมีจำนวนแถวมากจนตัวโปรแกรมและเครื่องคอมพิวเตอร์ที่เราใช้ไม่สามารถเปิดขึ้นมาได้ ไฟล์ CSV เป็นรูปแบบการจัดเก็บไฟล์ที่เรามักเลือกใช้หากข้อมูลมีขนาดใหญ่

## ดาตาเฟรม (dataframe) และการโหลดข้อมูลจากไฟล์

ดาตาเฟรม (dataframe) เป็นโครงสร้างข้อมูลหลักของ pandas ที่ใช้ในการจัดเก็บข้อมูลแบบตาราง เป็นโครงสร้างข้อมูลสองมิติที่คล้ายคลึงกับตารางข้อมูลที่ใช้ในโปรแกรม Excel หรือโปรแกรมตารางคำนวณอื่น ๆ ดาตาเฟรม ใช้เพื่อจัดเก็บข้อมูลในรูปแบบที่จัดระเบียบเป็นแถวและคอลัมน์ ซึ่งแต่ละแถวและคอลัมน์สามารถมีป้ายกำกับได้ เพราะฉะนั้นขั้นตอนแรกของการเตรียมข้อมูลสำหรับการวิเคราะห์ คือ การโหลดเอาข้อมูลมาใส่ในดาตาเฟรม

### การสร้างดาตาเฟรมจากลิสต์ของดิกชันนารี

การสร้างดาตาเฟรมจากลิสต์ของดิกชันนารีเป็นวิธีที่ถูกใช้ในหลายสถานการณ์ เมื่อทำงานกับไลบรารี pandas เช่น

- การแปลงข้อมูลจาก API หรือ JSON: ข้อมูลที่ได้จากการเรียกใช้ API หรือจากไฟล์ JSON มักจะอยู่ในรูปแบบของดิกชันนารีหรือลิสต์ของดิกชันนารี การแปลงโดยตรงเหล่านี้เข้าสู่ดาตาเฟรม ช่วยให้สามารถวิเคราะห์และประมวลผลข้อมูลได้ง่ายขึ้น
- การรวมข้อมูลจากหลายแหล่ง: ถ้ามีการรวบรวมข้อมูลจากหลาย ๆ แหล่งที่ให้รูปแบบข้อมูลที่ต่างกัน เรามักจะเขียนโค้ดเพิ่มเติมเพื่อรวบรวมเข้ามาใส่ดิกชันนารีซึ่งเป็นโครงสร้างข้อมูลที่ใช้ง่าย  การสร้างดาตาเฟรม จากลิสต์ของดิกชันนารีทำให้การรวมข้อมูลเหล่านี้เป็นกลุ่มก้อนเดียวกัน เพื่อนำมาแสดงผล และวิเคราะห์ได้อย่างสะดวกขึ้น

ตัวอย่าง สมมติว่าเรานำชื่อนักเรียนมาจากหน้าเว็บไซต์ และต้องการจัดเก็บข้อมูลนักเรียนเหล่านี้ในรูปแบบของดาตาเฟรม โดยมีคอลัมน์เป็นชื่อนักเรียนและอายุ ข้อมูลนักเรียนเหล่านี้จะถูกเก็บในลิสต์ของดิกชันนารี ดังนี้
```python
students = [{'student name': 'pang', 'age': 20}, 
     {'student name': 'dream', 'age': 19},
     {'student name':'tangmay', 'age': 19}
    ]
```
เราสามารถสร้างดาตาเฟรมจากลิสต์ของดิกชันนารีดังกล่าวได้โดยใช้ฟังก์ชัน `pd.DataFrame()` ดังนี้
```python
import pandas as pd
students = [{'student name': 'pang', 'age': 20}, 
     {'student name': 'dream', 'age': 19},
     {'student name':'tangmay', 'age': 19}
    ]
df = pd.DataFrame(students)
```
เมื่อรันโค้ดด้านบนเสร็จเรียบร้อย ค่าของตัวแปร `df` จะเป็นดาตาเฟรมที่มีคอลัมน์ `student name` และ `age` และมีแถวที่เก็บข้อมูลของนักเรียนทั้งหมด 3 คน ดังนี้
```
  student name  age
0         pang   20
1        dream   19
2      tangmay   19
```
ถ้าหากเรารันโค้ดข้างต้นบน Jupyter notebook หรือ Visual Studio Code หรือ Google Colab เครื่องจะแสดงผลตารางออกมาอย่างสวยงาม รวมถึงสามารถดูตารางแบบ interactive ใกล้เคียงกับการใช้งาน Excel ได้ หรือใช้ลูกเล่นในการสร้างกราฟอัตโนมัติต่อได้ แต่ถ้าเรารันโค้ดด้านบนบนโปรแกรมไพธอน ทั่วไป จะแสดงผลออกมาเป็นข้อความเท่านั้น 

### การสร้างดาตาเฟรมจากไฟล์ CSV

กรณีส่วนใหญ่ของการวิเคราะห์ข้อมูล เราจะต้องโหลดข้อมูลจากไฟล์ CSV ซึ่งเป็นรูปแบบไฟล์ที่ใช้งานกันอย่างแพร่หลาย เพราะใช้งานได้ง่าย ใช้งานได้ด้วยหลากหลายโปรแกรม pandas มีฟังก์ชัน `pd.read_csv()`  ซึ่งจะโหลดข้อมูลจากไฟล์ CSV และสร้างดาตาเฟรมจากข้อมูลที่ได้ ตัวอย่างเช่น ถ้าเรามีไฟล์ CSV ที่เก็บข้อมูลการรีวิวของผู้โดยสารของสายการบินต่าง ๆ ชื่อว่า `airline_reviews.csv` เราสามารถอ่านไฟล์ดังกล่าวและโหลดเข้ามาใส่ในดาตาเฟรม ดังนี้

```python
import pandas as pd
df = pd.read_csv('airline-reviews-small.csv')
```

ถ้าหากรันได้อย่างราบรื่น ไพธอนจะไม่แสดง error และตัวแปร `df` จะเป็นดาตาเฟรมที่เก็บข้อมูลจากไฟล์ CSV ที่เราโหลดเข้ามา โดยปกติแล้ว pandas จะอ่านไฟล์ CSV และสร้างดาตาเฟรมจากข้อมูลที่ได้ เรามักจะติดนิสัยการใช้ชื่อตัวแปร `df` ในการเก็บดาตาเฟรม เพราะว่าเป็นชื่อที่สั้น และชุมชนนักวิเคราะห์ข้อมูลนิยมใช้กัน แต่ผู้เขียนมีความเห็นว่าเราควรตั้งชื่อตัวแปรให้แสดงถึงชุดข้อมูลที่เราเก็บอยู่ เช่น `airline_reviews` หรือ `airline_reviews_small` จะช่วยให้เราเข้าใจว่าตัวแปรเก็บข้อมูลเป็นชุดข้อมูลของรีวิวของสายการบิน และเป็นดาตาเฟรม แน่นอนว่าชื่อตัวแปรเหล่านี้ยาวกว่าการเรียกว่า `df` เฉย ๆ แต่ว่าชื่อที่เหมาะสมจะช่วยให้เราเข้าใจโค้ดของเราได้ง่ายขึ้น รวมถึงในสมัยนี้เรามักใช้ IDE ที่ช่วยในการเติมชื่อตัวแปรให้ ความยาวของตัวแปรเองจึงไม่ควรจะเป็นประเด็นในการเลือกชื่อมากเหมือนก่อน เราจึงจะเรียกดาตาเฟรมที่เก็บข้อมูลรีวิวของสายการบินว่า `airline_reviews_small` ในตัวอย่างนี้
```python
import pandas as pd
airline_reviews_small = pd.read_csv('airline-reviews-small.csv')
```
ปัญหาที่พบบ่อยในการอ่านไฟล์ CSV คือ ไฟล์มีการจัดรูปแบบไม่เหมาะสม เช่น อาจจะไม่ได้ใช้จุลภาคในการแบ่งคอลัมน์จริง อาจจะใช้ `\t` เป็นอักขระคั่นแทนแต่ว่าใช้สกุลไฟล์เป็น .csv  หรือว่าแต่ละแถวมีจำนวนอักขระคั่นไม่เท่ากันทุกแถว ในกรณีเหล่านี้เราต้องเปิดไฟล์และตรวจสอบว่าข้อมูลถูกแบ่งอย่างถูกต้องหรือไม่ และแก้ไขข้อมูลด้วยมือให้ถูกต้องก่อนที่จะโหลดข้อมูลเข้ามาในดาตาเฟรม

## การตรวจสอบส่วนประกอบหลักของดาตาเฟรม
ส่วนประกอบหลักของดาตาเฟรมล้อไปกับส่วนประกอบหลักของข้อมูลแบบตาราง ได้แก่

1. แถว 
2. คอลัมน์
3. หัวตาราง 
4. ดัชนี (index)
5. ตัวข้อมูล

ในการเตรียมข้อมูลเบื้องต้น ควรมีการตรวจสอบข้อมูลดังนี้

### ตรวจสอบจำนวนแถวและคอลัมน์
เมื่อได้ข้อมูลมาทุกครั้งเราควรตรวจสอบว่าปริมาณข้อมูลตรงกับที่ควรจะเป็นหรือไม่ และมีปริมาณมากพอสำหรับการวิเคราะห์ที่ต้องการทำต่อไปหรือไม่ และจำนวนคอลัมน์ตรงกับที่พจนานุกรมข้อมูล หรือตรงกับจำนวนคอลัมน์ที่ควรจะเป็นหรือไม่ เราสามารถตรวจสอบจำนวนแถวและจำนวนคอลัมน์ของดาตาเฟรมได้โดยใช้ฟังก์ชัน `shape` ซึ่งจะแสดงจำนวนแถวและจำนวนคอลัมน์ของดาตาเฟรม ตัวอย่างเช่น
```python
airline_reviews_small.shape
```
จะแสดงผลลัพธ์ออกมาเป็นทูเปิลที่มีสมาชิกสองตัว คือ จำนวนแถวและจำนวนคอลัมน์ ตัวอย่างเช่น ถ้าดาตาเฟรม `airline_reviews_small` มี 10 แถว และ 5 คอลัมน์ ผลลัพธ์ที่ได้จะเป็น `(10, 5)`

หรือหากเราต้องการดูเฉพาะจำนวนแถวเพียงอย่างเดียวสามารถใช้คำสั่ง `len` ได้เหมือนกับการหาจำนวนข้อมูลในลิสต์ เช่น
```python
len(airline_reviews_small)
```
จะแสดงผลลัพธ์ออกมาเป็นจำนวนแถวของดาตาเฟรม 

### ตรวจสอบและแก้ไขหัวตาราง

เราควรเปลี่ยนชื่อคอลัมน์ที่อยู่ในหัวตารางให้สื่อความหมาย และเข้าใจง่าย หัวตารางของดาตาเฟรมจะถูกเก็บในรูปของลิสต์ของสตริง ซึ่งแสดงชื่อของคอลัมน์ หากเราต้องการดูหัวตารางของดาตาเฟรม เราสามารถใช้ฟังก์ชัน `columns` ได้ ตัวอย่างเช่น
```python
airline_reviews_small.columns
```
จะแสดงผลลัพธ์ออกมาเป็นอ็อบเจกต์ชื่อว่า `Index` แต่สามารถนำมาใช้ในลักษณะเดียวกันกับลิสต์ได้ ดังนี้
```
Index(['Airline Name', 'Rating', 'Seat Type', 'Verified', 'Date Flown'], dtype='object')
```
สังเกตได้ว่าคำสั่งไม่มี `()` ต่อท้าย ซึ่งแสดงว่าเป็นการเรียกลักษณะประจำ (attribute) ของดาตาเฟรม และไม่ใช่การเรียกฟังก์ชัน เพราะฉะนั้นเราสามารถเปลี่ยนชื่อคอลัมน์ทั้งหมด โดยให้ค่าใหม่กับลักษณะประจำได้ วิธีที่สะดวกที่สุดคือคัดลอกลิสต์ของชื่อคอลัมน์เดิมมา และแก้ไขชื่อคอลัมน์ที่ต้องการเปลี่ยน และให้ค่าใหม่กับลักษณะประจำ ตัวอย่างเช่น
```python
airline_reviews_small.columns = ['Airline Name', 'Rating', 'Seat Type', 'Verified', 'Date Flown', 'Review']
```
จากนั้นให้แก้สตริงที่อยู่ในลิสต์ตามที่เห็นควร เช่น
```python
airline_reviews_small.columns = ['Airline', 'Overall rating', 'Seat type', 'Verified', 'Date flown', 'Review text']
# เติมรูป
```
การแก้ไขหัวตารางหรือชื่อคอลัมน์ด้วยวิธีนี้มีข้อดี คือ ทำให้เราบันทึกชื่อคอลัมน์ทั้งหมดของตารางนี้ไว้ในโค้ดของเราโดยปริยาย ทำให้กลับมาดูโค้ดเราในภายหลังแล้วเข้าใจได้ง่าย และทราบทันทีว่าคอลัมน์มีชื่อว่าอะไรบ้าง 

แต่ถ้าหากตารางมีคอลัมน์เยอะมาก ๆ เราไม่อยากได้ลิสต์ที่ยาวมาก ๆ มาอยู่ในโค้ดของเรา เราสามารถใช้คำสั่ง `df.rename` ในการเปลี่ยนชื่อคอลัมน์ได้ เช่น

```python
airline_reviews_small.rename(columns={'Airline Name': 'Airline', 'Rating': 'Overall rating', 'Seat Type': 'Seat type', 'Date Flown': 'Date flown', 'Review': 'Review text'}, inplace=True)
# เติมรูป
```
สังเกตว่าคำสั่งมีการใช้พารามิเตอร์ `inplace=True` ซึ่งหมายความว่าเราจะแก้ไขคอลัมน์ในตัวดาตาเฟรมเดิม และไม่ได้สร้างดาตาเฟรมใหม่ขึ้นมา ถ้าเราไม่ใส่พารามิเตอร์นี้ คำสั่งจะสร้างดาตาเฟรมใหม่ที่มีคอลัมน์ที่แก้ไขแล้ว และเราต้องเก็บค่าใหม่ไว้ในตัวแปรใหม่ เช่น

```python
airline_reviews_small = airline_reviews_small.rename(columns={'Airline Name': 'Airline', 'Rating': 'Overall rating', 'Seat Type': 'Seat type', 'Date Flown': 'Date flown', 'Review': 'Review text'})
```

หากเราต้องการรันคำสั่งที่มีการเปลี่ยนแปลงค่าของตัวดาตาเฟรม เราควรรันคำสั่งโดยไม่ตั้ง `inplace=True` ก่อน และให้ Jupyter notebook แสดงผลออกมาและตรวจสอบว่าผลตรงกับที่คาดหวังหรือไม่ จากนั้นค่อยรันคำสั่งเดิม แต่ตั้ง `inplace=True` และรันอีกครั้ง 

### ตรวจสอบและแปลงแบบชนิดของข้อมูลให้ถูกต้อง

ตัวข้อมูลที่อยู่ในคอลัมน์เดียวกันในดาตาเฟรมของ pandas จะต้องมีชนิดของข้อมูลเดียวกัน นั่นเป็นเพราะว่าการประมวลผลข้อมูลใน pandas จะมีประสิทธิภาพมากขึ้นเมื่อข้อมูลในคอลัมน์นั้นเป็นประเภทเดียวกัน เช่น ตัวเลขทั้งหมดหรือข้อความทั้งหมด หากมีการผสมกันของชนิดข้อมูลในคอลัมน์เดียวกัน อาจทำให้เกิดข้อผิดพลาดในการคำนวณและวิเคราะห์ข้อมูล

ยกตัวอย่างเช่น หากเรามีคอลัมน์ที่ควรจะเก็บตัวเลขเพื่อนำมาหาค่าสถิติ แต่กลับมีตัวอักษรปนอยู่ เมื่อเราพยายามหาค่าเฉลี่ย (mean) ของคอลัมน์นั้น การคำนวณจะไม่สามารถทำได้ เนื่องจากการหาค่าเฉลี่ยต้องการข้อมูลที่เป็นตัวเลขทั้งหมด การมีตัวข้อมูลที่เป็นตัวอักษรในคอลัมน์จะทำให้เกิดข้อผิดพลาดในการคำนวณ ดังนั้น การรักษาความเป็นหนึ่งเดียวของชนิดข้อมูลในคอลัมน์จึงเป็นสิ่งสำคัญ เพื่อให้เราสามารถใช้ประโยชน์จากฟังก์ชันต่าง ๆ ของ pandas ได้อย่างเต็มที่ 

เราสามารถตรวจสอบชนิดของข้อมูลในคอลัมน์ของดาตาเฟรมได้โดยใช้ฟังก์ชัน `dtypes` ซึ่งจะแสดงชนิดของข้อมูลของแต่ละคอลัมน์ ตัวอย่างเช่น
```python
airline_reviews_small.dtypes
```
จะแสดงผลลัพธ์ออกมาเป็นชนิดของข้อมูลของแต่ละคอลัมน์ ตัวอย่างเช่น
```
Airline Name    object
Rating          float64
Seat Type        object
Verified           bool
Date Flown      object
dtype: object
```

ผลลัพธ์ที่ได้จะออกมาเป็นโครงสร้างข้อมูลที่เรียกว่า `Series` ซึ่งเป็นโครงสร้างข้อมูลที่คล้ายคลึงกับลิสต์ แต่ว่าสมาชิกแต่ละตัวจะมีค่าดัชนี (index) ซึ่งเปรียบได้กับชื่อที่เราให้กับสมาชิกแต่ละตัวใน `Series` ในผลลัพธ์ข้างต้น ชนิดของข้อมูลของแต่ละคอลัมน์ถูกแสดงออกมา โดยใช้ชื่อของคอลัมน์เป็นดัชนี และชนิดของข้อมูลเป็นค่าที่เก็บอยู่ใน `Series` นั้น ๆ  คอลัมน์ `Airline Name` และ `Seat Type` มีแบบชนิดของข้อมูลเป็น `object` ซึ่งหมายความว่าเป็นข้อความหรือตัวแปรจำแนกประเภท (categorical variable) คอลัมน์ `Rating` มีแบบชนิดของข้อมูลเป็น `float64` ซึ่งหมายความว่าเป็นตัวเลขที่มีทศนิยม คอลัมน์ `Verified` มีแบบชนิดของข้อมูลเป็น `bool` ซึ่งหมายความว่าเป็นข้อมูลที่มีค่าเป็นจริงหรือเท็จ และคอลัมน์ `Date Flown` มีแบบชนิดของข้อมูลเป็น `object` ซึ่งหมายความว่าเป็นข้อความ

แบบชนิดของข้อมูลที่ `Series` รองรับมีหลายแบบ แบบชนิดที่ใช้บ่อยที่สุดได้แก่

1. `int64` สำหรับข้อมูลตัวเลขจำนวนเต็ม
2. `float64` สำหรับข้อมูลตัวเลขที่มีทศนิยม
3. `bool` สำหรับข้อมูลที่มีค่าเป็นจริงหรือเท็จ
4. `datetime64` สำหรับข้อมูลวันที่และเวลา
5. `category` สำหรับข้อมูลที่เป็นตัวแปรจำแนกประเภท
6. `object` สำหรับข้อมูลที่เป็นข้อความหรือข้อมูลที่ไม่เข้ากับแบบชนิดของข้อมูลอื่น ๆ

แต่ในพจนานุกรมข้อมูลบอกว่าคอลัมน์ `Rating` ควรจะเป็นชนิดของข้อมูล `int64` เนื่องจากผู้ที่ให้ความเห็นให้คะแนนมาเป็นจำนวนเต็ม คอลัมน์ `Seat Type` ควรจะเป็นชนิดของข้อมูล `category` เนื่องจากมีค่าที่เป็นตัวแปรจำแนกประเภทที่มีค่าที่เป็นไปได้ 4 แบบ ไม่ใช่ข้อความที่เขียนได้อย่างอิสระ
และคอลัมน์ `Date Flown` ควรจะเป็นชนิดของข้อมูล `datetime64` เนื่องจากเป็นวันที่ ไม่ใช่ข้อความอิสระ ดังนั้นเราจำเป็นต้องแปลงชนิดของข้อมูลให้ถูกต้องก่อนที่จะดำเนินการวิเคราะห์ข้อมูลต่อไป การแปลงชนิดของข้อมูลใน pandas สามารถทำได้โดยใช้ฟังก์ชัน `astype()` โดยใส่ชื่อแบบชนิดของข้อมูลเข้ามาเป็นพารามิเตอร์ ตัวอย่างเช่น
```python
airline_reviews_small['Rating'] = airline_reviews_small['Rating'].astype('int64')
airline_reviews_small['Seat Type'] = airline_reviews_small['Seat Type'].astype('category')
airline_reviews_small['Date Flown'] = pd.to_datetime(airline_reviews_small['Date Flown'])
```

ในตัวอย่างข้างต้น เราแปลงชนิดของข้อมูลในคอลัมน์ `Rating` จาก `float64` เป็น `int64` คอลัมน์ `Seat Type` จาก `object` เป็น `category`
และแปลงชนิดของข้อมูลในคอลัมน์ `Date Flown` จาก `object` เป็น `datetime64` โดยใช้ฟังก์ชัน `astype()` และ `pd.to_datetime()` ตามลำดับ

จากนั้นให้เราตรวจสอบแบบชนิดของทุกคอลัมน์อีกครั้ง ด้วยคำสั่ง `airline_reviews_small.dtypes()`
```
Airline Name            object
Rating                   int64
Seat Type             category
Verified                  bool
Date Flown      datetime64[ns]
Review                  object
dtype: object
```

## การทำความสะอาดข้อมูล
การทำความสะอาดข้อมูล (data cleaning) เป็นขั้นตอนที่สำคัญในการเตรียมข้อมูลเพื่อนำมาวิเคราะห์ ประกอบไปด้วยการตรวจสอบความครบถ้วนว่ามีแถวหรือคอลัมน์ใดหรือไม่ที่ไม่มีตัวข้อมูลอยู่ และการตรวจสอบความถูกต้องมีแถวหรือคอลัมน์ใดหรือไม่ที่มีข้อมูลที่ไม่ถูกต้องอยู่  

### การตรวจหาข้อมูลที่หายไป

ข้อมูลที่หายไป (missing data) คือข้อมูลที่ไม่มีค่าในคอลัมน์ หรือข้อมูลที่มีค่าเป็น `NaN` ใน pandas ข้อมูลที่หายไปจะมีผลกระทบต่อการวิเคราะห์ข้อมูล และการสร้างโมเดลที่ถูกต้อง การตรวจหาข้อมูลที่หายไปสามารถทำได้โดยใช้ฟังก์ชัน `isnull()` หรือ `isna()` ซึ่งจะแสดงข้อมูลที่หายไปในรูปของ `Series` ที่มีค่าเป็น `True` หรือ `False` ตามที่ข้อมูลหายไปหรือไม่ จากนั้นเราจึงพิจารณาการบริบทของเก็บข้อมูลของชุดข้อมูลนี้ และตัดสินใจว่าควรจะเติมค่าอะไรเข้าไป หรือว่าควรจะลบแถวหรือคอลัมน์ที่มีข้อมูลที่หายไปออกไป

ในบริบทของการวิเคราะห์ข้อมูลด้วย pandas คำว่า NaN หมายถึง "Not a Number" ซึ่งเป็นค่าที่ใช้แทนข้อมูลที่หายไปหรือข้อมูลที่ไม่สามารถแสดงเป็นตัวเลขได้ ในการทำงานกับข้อมูลที่เป็นเชิงปริมาณ NaN จะถูกใช้บ่อยในการจัดการกับข้อมูลที่ขาดหายไป ตัวอย่างเช่น หากเรามีชุดข้อมูลของคะแนนสอบนักเรียน และบางคนไม่ได้เข้าสอบ คะแนนเหล่านี้อาจถูกแทนที่ด้วย NaN สืบเนื่องจากไฟล์ CSV หรือ Excel อาจจะบันทึกข้อมูลของนักเรียนที่ขาดสอบเป็นเซลล์ว่าง ๆ แทนที่จะใส่ค่าเป็น 0 ไปซึ่งอาจจะแปลว่า เข้าสอบแต่ว่าตอบข้อสอบผิดทุกข้อ 

ฟังก์ชัน `isnull()` และ `isna()` ใช้สำหรับตรวจสอบข้อมูลที่หายไปในดาตาเฟรมโดยจะคืนค่าเป็นดาตาเฟรมที่มีค่าเป็น `True` หากข้อมูลในช่องนั้นเป็น NaN และเป็น `False` หากข้อมูลมีค่า ตัวอย่างเช่น หากเรามีดาตาเฟรมที่มีข้อมูลคะแนนสอบและมีบางช่องที่ตัวข้อมูลหายไป เมื่อใช้ `isnull()` เราจะเห็นว่าในช่องที่ไม่มีค่าจะแสดงเป็น `True` ฟังก์ชัน `isna()` มีการทำงานที่เหมือนกับ `isnull()` ทุกประการ การใช้งานทั้งสองฟังก์ชันนี้ไม่ได้มีความแตกต่างกันในเชิงปฏิบัติ ทั้งคู่สามารถใช้แทนกันได้ ขึ้นอยู่กับความชอบส่วนบุคคลในการเขียนโค้ดหรือการอ่านโค้ด

สมมติว่าเราได้ข้อมูลที่มีค่าที่หายไปอยู่ในไฟล์ CSV (ข้อมูลแต่ละบรรทัดลดเหลือเพียงบรรทัดละ 75 ตัวอักษรเพื่อที่จะแสดงผลบนหน้าจอและกระดาษได้พอดี) ดังนี้
```
Airline Name,Rating,Seat Type,Verified,Date Flown,Review
Bangkok Airways,6,Economy,TRUE,March 2019,"For this flight I was connec...
Bangkok Airways,9,Economy,TRUE,June 2019,"Bangkok to Koh Samui. Easy Ch...
Bangkok Airways,,,FALSE,November 2021,"I just want to thank Bangkok Air...
Bangkok Airways,9,Economy,FALSE,April 2020,"I especially want to thank ...
Garuda Indonesia,1,Economy,TRUE,July 2023,"Flew on GA-682 Jakarta to So...
Garuda Indonesia,9,Business,TRUE,,"Jakarta to Sorong. Check in was stra...
Garuda Indonesia,9,Business,TRUE,February 2020,"Flew Jakarta-Sorong on ...
Philippine Airlines,8,,TRUE,April 2023,"This was the second flight in 7...
Philippine Airlines,7,Premium Economy,FALSE,January 2023,Got Premium ec...
Philippine Airlines,1,Economy,TRUE,July 2023,"Miserable experience: ver...
```
จากข้อมูลด้านบน เราสังเกตหาข้อมูลที่หายไปค่อนข้างยาก และในการใช้งานจริงข้อมูลมักจะมีขนาดใหญ่มากจนเราไม่ได้มองหาข้อมูลที่หายไปด้วยตาเปล่าได้ ในกรณีนี้เราสามารถใช้ฟังก์ชัน `isnull()` หรือ `isna()` ในการตรวจสอบข้อมูลที่หายไปได้

ตัวอย่างเช่น
```python
bad_df = pd.read_csv('airlines-reviews-small-missing.csv')
bad_df.isnull()
```

```{figure} img/df-null.png
(บน) ดาตาเฟรมที่มีข้อมูลที่หายไป แทนค่าด้วย NaN

(ล่าง) ดาตาเฟรมที่ถูกคืนค่ามาจากคำสั่ง `.isnull()`

 (ข้อมูลดัดแปลงจาก Airline Reviews Dataset จาก airlinequality.com)
```


ผลที่ได้จะเป็นดาตาเฟรมที่เต็มไปด้วยค่า `True` และ `False` ซึ่งยังไม่ได้ช่วยให้เรามองหาช่องที่มีข้อมูลที่หายไปได้ แต่เราสามารถใช้ฟังก์ชัน `sum()` ในการนับจำนวนข้อมูลที่หายไปในแต่ละคอลัมน์ได้ ตัวอย่างเช่น

```python
airline_reviews_small.isnull().sum(axis=0)
```
```{figure} img/df-null-sum-0.png
หาผลรวมของบูลีนที่อยู่ในแต่ละคอลัมน์ (ข้อมูลดัดแปลงจาก Airline Reviews Dataset จาก airlinequality.com)
```
คำสั่งข้างต้นทำความเข้าใจได้ยากเล็กน้อย เพราะมีการเรียกสองเมท็อดต่อเนื่องกันในบรรทัดเดียว เราเรียกวิธีนี้ว่าการโยงเมท็อด (method chaining) ซึ่งการเรียกเมท็อดต่อเนื่องกันโดยไม่ต้องเก็บผลลัพธ์ของเมท็อดก่อนหน้าไว้ในตัวแปรก่อน และเรียกเมท็อดต่อไปได้ทันที ในตัวอย่างข้างต้นเราให้ดาตาเฟรมเรียกเมท็อด `isnull()` ก่อน และให้ผลลัพธ์เป็นดาตาเฟรม จากนั้นใช้ดาตาเฟรมนั้นเมท็อด `sum()` ต่อ โดยให้พารามิเตอร์ `axis=0` ซึ่งหมายถึงให้ฟังก์ชัน `sum()` นับจำนวนข้อมูลที่หายไปในแต่ละคอลัมน์ ดังนั้นจึงมีค่าเท่ากับการเรียกเมท็อดแยกกัน โดยใช้คำสั่งดังนี้

```python
empty_boolean_df = airline_reviews_small.isnull()
empty_boolean_df.sum(axis=0)
```
การเรียกโค้ดโดยวิธีข้างต้นได้ผลลัพธ์ออกมาเหมือนกัน แต่ว่าโค้ดจะยาวกว่าเล็กน้อย และมีความชัดเจนมากขึ้น ซึ่งก็ขึ้นอยู่กับความชอบส่วนตัวของแต่ละคนว่าต้องการใช้การโยงเมท็อดหรือไม่ แต่ว่าการใช้วิธีการโยงเมท็อดนี้เป็นที่นิยมในการเขียนโค้ดของ pandas เพราะว่าโค้ดสั้นกว่าและเข้่าใจง่ายสำหรับคนที่เขียนโค้ดค่อนข้างคล่องแล้ว
```{margin} คำศัพท์
การโยงเมท็อด (method chaining) หมายถึงการเรียกเมท็อดต่อเนื่องกันโดยไม่ต้องเก็บผลลัพธ์ของเมท็อดก่อนหน้าไว้ในตัวแปรก่อน และเรียกเมท็อดต่อไปได้ทันที
```

ผลลัพธ์ที่ได้จากทั้งสองวิธีจะเป็นจำนวนข้อมูลที่หายไปในแต่ละคอลัมน์ คืนค่ามาเป็น `Series` ที่ index เป็นชื่อคอลัมน์ของดาตาเฟรมเดิมดังนี้
```
Airline Name    0
Rating          1
Seat Type       2
Verified        0
Date Flown      1
Review          0
dtype: int64
```
จากผลลัพธ์ที่ได้ เราสามารถเห็นได้ว่าคอลัมน์ `Rating` มีข้อมูลที่หายไป 1 ค่า คอลัมน์ `Seat Type` มีข้อมูลที่หายไป 2 ค่า และคอลัมน์ `Date Flown` มีข้อมูลที่หายไป 1 ค่า แต่คอลัมน์ `Airline Name` และ `Verified` ไม่มีข้อมูลที่หายไปเลย

ในลักษณะเดียวกัน เราสามารถคำนวณจำนวนแถวที่มีข้อมูลที่หายไปได้โดยใช้ฟังก์ชัน `sum()` โดยกำหนด `axis=1` ซึ่งหมายถึงให้ฟังก์ชัน `sum()` นับจำนวนข้อมูลที่หายไปในแต่ละแถว ตัวอย่างเช่น
```python
airline_reviews_small.isnull().sum(axis=1)
```
```{figure} img/df-null-sum-1.png
หาผลรวมของบูลีนที่อยู่ในแต่ละแถว (ข้อมูลดัดแปลงจาก Airline Reviews Dataset จาก airlinequality.com)
```
ผลลัพธ์ที่ได้จะเป็นจำนวนข้อมูลที่หายไปในแต่ละแถว คืนค่ามาเป็น `Series` ที่ index เป็นชื่อแถวของดาตาเฟรมเดิมดังนี้
```
0    0
1    0
2    2
3    0
4    0
5    1
6    0
7    1
8    0
9    0
dtype: int64
```
จากผลลัพธ์ที่ได้ เราสามารถเห็นได้ว่าแถวที่ 2 มีข้อมูลที่หายไป 2 ค่า และแถวที่ 5 มีข้อมูลที่หายไป 1 ค่า แต่แถวอื่น ๆ ไม่มีข้อมูลที่หายไปเลย

แต่ถ้าหากดาตาเฟรมมีจำนวนแถวเยอะมาก เราเพียงต้องการทราบว่ามีกี่แถวที่มีข้อมูลที่หายไปอย่างน้อยหนึ่งช่อง ในกรณีนี้เราสามารถใช้ฟังก์ชัน `any()` หรือ `all()` เพื่อดูถามว่าแต่แถวนั้นมี `True` อย่างน้อยหนึ่งตัวหรือไม่ โดยกำหนด `axis=1` ในการตรวจสอบข้อมูลที่หายไปในแต่ละแถว ตัวอย่างเช่น
```python
airline_reviews_small.isnull().any(axis=1).sum()
```
```{figure} img/df-null-any-sum.png
หาจำนวนแถวที่มีช่องที่ข้อมูลหายไปอย่างน้อยหนึ่งช่องโดยการโยงเมท็อดสามเมท็อด (ข้อมูลดัดแปลงจาก Airline Reviews Dataset จาก airlinequality.com)
```

`airline_reviews_small.isnull().any(axis=1)` จะคืนค่าเป็น `Series` ที่มีค่าเป็น `True` หากแถวนั้นมีข้อมูลที่หายไปอย่างน้อยหนึ่งช่อง และ `False` หากแถวนั้นไม่มีข้อมูลที่หายไปเลย ตัวอย่างเช่น
```
0    False
1    False
2     True
3    False
4    False
5     True
6    False
7     True
8    False
9    False
dtype: bool
```
เมื่อได้ผลลัพธ์ข้างต้นแล้วเราสามารถหาผลรวมของจำนวนแถวที่มีข้อมูลที่หายไปอย่างน้อยหนึ่งช่องได้ โดยใช้ฟังก์ชัน `sum()` ต่อท้าย ซึ่งจะคืนค่าเป็นจำนวนแถวที่มีข้อมูลที่หายไปอย่างน้อยหนึ่งช่อง 



### การแก้ไขข้อมูลที่หายไป

การแก้ไขข้อมูลที่หายไป สามารถทำได้โดยใช้ฟังก์ชัน `fillna()` ซึ่งจะแทนที่ข้อมูลที่หายไปด้วยค่าที่เรากำหนด หรือใช้ฟังก์ชัน `dropna()` ซึ่งจะลบแถวที่มีข้อมูลที่หายไปออกไป ตัวอย่างเช่น
```python
airline_reviews_small['Rating'] = airline_reviews_small['Rating'].fillna(0)
```

```python
airline_reviews_small.dropna(subset=['Airline Name', 'Rating', 'Seat Type', 'Date Flown'], inplace=True)
```



### การทำความสะอาดข้อมูลที่เป็นข้อมูลตัวเลข



### การทำความสะอาดข้อมูลที่เป็นข้อมูลที่เป็นตัวแปรจำแนกประเภท


### การทำความสะอาดข้อมูลที่เป็นข้อมูลข้อความ

